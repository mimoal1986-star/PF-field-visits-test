# utils/data_cleaner.py
# draft 1.8
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import re
import streamlit as st
import io


class DataCleaner:

    def _find_column(self, df, possible_names):
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–æ–ª–æ–Ω–∫—É –ø–æ –≤–æ–∑–º–æ–∂–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º"""
        for name in possible_names:
            if name in df.columns:
                return name
        return None
    
    def clean_google(self, df):
        """
        –®–∞–≥–∏ 1-7: –û—á–∏—Å—Ç–∫–∞ –ì—É–≥–ª —Ç–∞–±–ª–∏—Ü—ã (–ü—Ä–æ–µ–∫—Ç—ã –°–µ—Ä–≤–∏–∑–æ—Ä–∏—è)
        """
        if df is None or df.empty:
            st.warning("‚ö†Ô∏è –ì—É–≥–ª —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None
        
        df_clean = df.copy()
        original_rows = len(df_clean)
        original_cols = len(df_clean.columns)
        
        st.info(f"üßπ –ù–∞—á–∏–Ω–∞—é –æ—á–∏—Å—Ç–∫—É –ì—É–≥–ª —Ç–∞–±–ª–∏—Ü—ã: {original_rows} —Å—Ç—Ä–æ–∫ √ó {original_cols} –∫–æ–ª–æ–Ω–æ–∫")
        
        # === –®–ê–ì 1: –£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –∑–∞–ø–∏—Å–µ–π ===
        st.write("**1Ô∏è‚É£ –£–¥–∞–ª—è—é –¥—É–±–ª–∏–∫–∞—Ç—ã –∑–∞–ø–∏—Å–µ–π...**")
        
        # –ò—â–µ–º –ø–æ–ª—è —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
        code_field = self._find_column(df_clean, [
            '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ RU00.000.00.01SVZ24',  # –û—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        ])
        
        start_date_field = self._find_column(df_clean, [
            '–î–∞—Ç–∞ —Å—Ç–∞—Ä—Ç–∞', # –û—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        ])
        
        end_date_field = self._find_column(df_clean, [
            '–î–∞—Ç–∞ —Ñ–∏–Ω–∏—à–∞ —Å –ø—Ä–æ–¥–ª–µ–Ω–∏–µ–º',  # –û—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        ])
        
        # –°–æ–±–∏—Ä–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ–ª—è
        existing_fields = []
        field_display_names = []
        
        if code_field:
            existing_fields.append(code_field)
            field_display_names.append('–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞')
            
        if start_date_field:
            existing_fields.append(start_date_field)
            field_display_names.append('–î–∞—Ç–∞ —Å—Ç–∞—Ä—Ç–∞')
            
        if end_date_field:
            existing_fields.append(end_date_field)
            field_display_names.append('–î–∞—Ç–∞ —Ñ–∏–Ω–∏—à–∞')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –ø–æ–ª–µ–π –Ω–∞—à–ª–æ—Å—å
        if len(existing_fields) == 3:
            before = len(df_clean)
            df_clean = df_clean.drop_duplicates(subset=existing_fields, keep='first') # —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∑–∞–ø–∏—Å–µ–π
            after = len(df_clean)
            removed = before - after
            
            if removed > 0:
                st.success(f"   ‚úÖ –£–¥–∞–ª–µ–Ω–æ {removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
                st.info(f"   –ü–æ –ø–æ–ª—è–º: {', '.join(field_display_names)}")
                st.info(f"   –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∏–º–µ–Ω–∞: {', '.join(existing_fields)}")
            else:
                st.info("   ‚ÑπÔ∏è –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                
        elif len(existing_fields) >= 1:
            st.warning(f"   ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ {len(existing_fields)} –∏–∑ 3 –ø–æ–ª–µ–π: {', '.join(field_display_names)}")
                
        else:
            st.warning("   ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ –ø–æ–ª—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
            st.info("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –≤ —Ñ–∞–π–ª–µ")
            
        
        # === –®–ê–ì 2: –°–∂–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–¥–∞—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ ===
        st.write("**2Ô∏è‚É£ –ß–∏—â—É –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–¥–∞—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤...**")
        
        code_col = self._find_column(df_clean, ['–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ RU00.000.00.01SVZ24'])
        
        if code_col:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            original_codes = df_clean[code_col].copy()
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ
            df_clean[code_col] = df_clean[code_col].astype(str)
            
            # –¢–û–õ–¨–ö–û —É–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ (–ø–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏)
            df_clean[code_col] = df_clean[code_col].str.strip()
            
            # –°—á–∏—Ç–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            changed = (original_codes.fillna('') != df_clean[code_col].fillna('')).sum()
            if changed > 0:
                st.success(f"   ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {changed} –∫–æ–¥–æ–≤ –ø—Ä–æ–µ–∫—Ç–æ–≤ (—É–¥–∞–ª–µ–Ω—ã –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ)")
            else:
                st.info("   ‚ÑπÔ∏è –ü—Ä–æ–±–µ–ª—ã –≤ –∫–æ–¥–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        else:
            st.warning("   ‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ —Å –∫–æ–¥–æ–º –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # === –®–ê–ì 3: –ó–∞–ø–æ–ª–Ω–∏—Ç—å –ø—É—Å—Ç—ã–µ –∫–æ–¥—ã –ø—Ä–æ–µ–∫—Ç–æ–≤ ===
        st.write("**3Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä—è—é –ø—É—Å—Ç—ã–µ –∫–æ–¥—ã –ø—Ä–æ–µ–∫—Ç–æ–≤...**")
        
        if code_col:
            empty_mask = (
                df_clean[code_col].isna() | 
                (df_clean[code_col].astype(str).str.strip() == '') |
                (df_clean[code_col].astype(str).str.strip() == 'nan') |
                (df_clean[code_col].astype(str).str.strip() == 'None')
            )
            
            empty_count = empty_mask.sum()
            if empty_count > 0:
                st.warning(f"   ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {empty_count} –ø—Ä–æ–µ–∫—Ç–æ–≤ –±–µ–∑ –∫–æ–¥–∞")
            else:
                st.info("   ‚ÑπÔ∏è –ü—É—Å—Ç—ã—Ö –∫–æ–¥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                
        
        # === –®–ê–ì 4: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –ü–∏–ª–æ—Ç—ã/–°–µ–º–ø–ª—ã/–ú—É–ª—å—Ç–∏–∫–æ–¥—ã ===
        st.write("**4Ô∏è‚É£ –§–æ—Ä–º–∞—Ç–∏—Ä—É—é –ü–∏–ª–æ—Ç—ã/–°–µ–º–ø–ª—ã/–ú—É–ª—å—Ç–∏–∫–æ–¥—ã...**")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ –∏–∑ —à–∞–≥–∞ 2 –µ—Å–ª–∏ –µ—Å—Ç—å
        if 'code_col' in locals() and code_col:
            target_col = code_col
        else:
            target_col = self._find_column(df_clean, ['–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ RU00.000.00.01SVZ24'])
        
        if target_col:
            changes_count = 0
            target_values = ['–ø–∏–ª–æ—Ç', '—Å–µ–º–ø–ª', '–º—É–ª—å—Ç–∏–∫–æ–¥']
            
            for idx, value in df_clean[target_col].items():
                if pd.isna(value):
                    continue
                    
                str_value = str(value).strip()
                lower_value = str_value.lower()
                
                for target in target_values:
                    if target in lower_value:
                        formatted_value = str_value.capitalize() if str_value else str_value
                        
                        if formatted_value != str_value:
                            df_clean.at[idx, target_col] = formatted_value
                            changes_count += 1
                            break
            
            if changes_count > 0:
                st.success(f"   ‚úÖ –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–æ {changes_count} –∑–Ω–∞—á–µ–Ω–∏–π")
                st.info("   –ü—Ä–∏–º–µ—Ä: '–ø–∏–õ–æ—Ç' ‚Üí '–ü–∏–ª–æ—Ç', '–°–ï–ú–ü–õ' ‚Üí '–°–µ–º–ø–ª'")
            else:
                st.info("   ‚ÑπÔ∏è –ó–Ω–∞—á–µ–Ω–∏—è —É–∂–µ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω—ã")
        else:
            st.warning("   ‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ —Å –∫–æ–¥–æ–º –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # === –®–ê–ì 5: –ó–∞–ø–æ–ª–Ω–∏—Ç—å –ø—É—Å—Ç—ã–µ –¥–∞—Ç—ã ===
        st.write("**5Ô∏è‚É£ –ó–∞–ø–æ–ª–Ω—è—é –ø—É—Å—Ç—ã–µ –¥–∞—Ç—ã...**")

        # –¢–û–õ–¨–ö–û —ç—Ç–∏ 2 –∫–æ–ª–æ–Ω–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –¥–∞—Ç—ã
        date_cols_to_process = []
        for col_name in ['–î–∞—Ç–∞ —Å—Ç–∞—Ä—Ç–∞', '–î–∞—Ç–∞ —Ñ–∏–Ω–∏—à–∞ —Å –ø—Ä–æ–¥–ª–µ–Ω–∏–µ–º']:
            if col_name in df_clean.columns:
                date_cols_to_process.append(col_name)
            else:
                # –ò—â–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–∑–≤–∞–Ω–∏–π
                found = self._find_column(df_clean, [col_name])
                if found:
                    date_cols_to_process.append(found)
        
        date_cols = date_cols_to_process

        
        if date_cols:
            date_fixes = 0
            
            for col in date_cols:
                try:
                    df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce', dayfirst=True)
                    empty_dates = df_clean[col].isna().sum()
                    
                    if empty_dates > 0:
                        col_lower = str(col).lower()
                        is_start_date = any(word in col_lower for word in ['—Å—Ç–∞—Ä—Ç', '–Ω–∞—á–∞–ª', 'start'])
                        is_end_date = any(word in col_lower for word in ['—Ñ–∏–Ω–∏—à', '–∫–æ–Ω–µ—Ü', 'end', '–∑–∞–≤–µ—Ä—à'])
                        current_date = pd.Timestamp.now()
                        
                        for idx in df_clean[df_clean[col].isna()].index:
                            if is_start_date:
                                df_clean.at[idx, col] = current_date.replace(day=1)
                            elif is_end_date:
                                next_month = current_date.replace(day=28) + timedelta(days=4)
                                df_clean.at[idx, col] = next_month - timedelta(days=next_month.day)
                            else:
                                df_clean.at[idx, col] = current_date
                        
                        date_fixes += empty_dates
                        st.info(f"   –ó–∞–ø–æ–ª–Ω–µ–Ω–æ {empty_dates} –ø—É—Å—Ç—ã—Ö –¥–∞—Ç –≤ '{col}'")
                except Exception as e:
                    st.warning(f"   –û—à–∏–±–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ '{col}': {str(e)[:100]}")
            
            if date_fixes > 0:
                st.success(f"   ‚úÖ –ó–∞–ø–æ–ª–Ω–µ–Ω–æ {date_fixes} –ø—É—Å—Ç—ã—Ö –¥–∞—Ç")
            else:
                st.info("   ‚ÑπÔ∏è –ü—É—Å—Ç—ã—Ö –¥–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        else:
            st.warning("   ‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # === –®–ê–ì 6: –ò—Å–ø—Ä–∞–≤–∏—Ç—å –¥–∞—Ç—ã –ø–æ –±–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞–º ===
        st.write("**6Ô∏è‚É£ –ü—Ä–∏–º–µ–Ω—è—é –±–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –¥–∞—Ç...**")
        
        date_rules_applied = 0
        today = pd.Timestamp.now()
        first_day_current_month = today.replace(day=1, hour=0, minute=0, second=0)
        next_month = today.replace(day=28) + timedelta(days=4)
        last_day_current_month = next_month - timedelta(days=next_month.day)
        
        for col in date_cols:
            if col not in df_clean.columns:
                continue
                
            col_lower = str(col).lower()
            
            if any(word in col_lower for word in ['—Å—Ç–∞—Ä—Ç', '–Ω–∞—á–∞–ª', 'start']):
                try:
                    if df_clean[col].dtype != 'datetime64[ns]':
                        df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce', dayfirst=True)
                    
                    mask = df_clean[col] < first_day_current_month
                    
                    if mask.any():
                        df_clean.loc[mask, col] = first_day_current_month
                        date_rules_applied += mask.sum()
                        st.info(f"   –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {mask.sum()} –¥–∞—Ç —Å—Ç–∞—Ä—Ç–∞")
                except Exception as e:
                    st.warning(f"   –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞—Ç—ã —Å—Ç–∞—Ä—Ç–∞ –≤ '{col}': {str(e)[:100]}")
            
            elif any(word in col_lower for word in ['—Ñ–∏–Ω–∏—à', '–∫–æ–Ω–µ—Ü', 'end']):
                try:
                    if df_clean[col].dtype != 'datetime64[ns]':
                        df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce', dayfirst=True)
                    
                    mask = df_clean[col] > last_day_current_month
                    
                    if mask.any():
                        df_clean.loc[mask, col] = last_day_current_month
                        date_rules_applied += mask.sum()
                        st.info(f"   –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {mask.sum()} –¥–∞—Ç —Ñ–∏–Ω–∏—à–∞")
                except Exception as e:
                    st.warning(f"   –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞—Ç—ã —Ñ–∏–Ω–∏—à–∞ –≤ '{col}': {str(e)[:100]}")

        # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—à–∏–±–æ–∫ –≤ –≥–æ–¥–µ ===
        st.info("   üîç –ü—Ä–æ–≤–µ—Ä—è—é –æ—à–∏–±–∫–∏ –≤ –≥–æ–¥–µ –¥–∞—Ç...")
        
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å—Ç–∞—Ä—Ç–∞ –∏ —Ñ–∏–Ω–∏—à–∞
        start_date_cols = []
        end_date_cols = []
        
        for col in date_cols:
            col_lower = str(col).lower()
            if any(word in col_lower for word in ['—Å—Ç–∞—Ä—Ç', '–Ω–∞—á–∞–ª', 'start']):
                start_date_cols.append(col)
            elif any(word in col_lower for word in ['—Ñ–∏–Ω–∏—à', '–∫–æ–Ω–µ—Ü', 'end']):
                end_date_cols.append(col)
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –æ–±–µ –∫–æ–ª–æ–Ω–∫–∏
        if start_date_cols and end_date_cols:
            for start_col in start_date_cols:
                for end_col in end_date_cols:
                    try:
                        # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ –æ–±–µ –∫–æ–ª–æ–Ω–∫–∏ - datetime
                        if (df_clean[start_col].dtype == 'datetime64[ns]' and 
                            df_clean[end_col].dtype == 'datetime64[ns]'):
                            
                            # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫–∏ –≥–¥–µ —Ñ–∏–Ω–∏—à —Ä–∞–Ω—å—à–µ —Å—Ç–∞—Ä—Ç–∞
                            mask = df_clean[end_col] < df_clean[start_col]
                            
                            if mask.any():
                                corrected_count = 0
                                
                                for idx in df_clean[mask].index:
                                    start_date = df_clean.at[idx, start_col]
                                    end_date = df_clean.at[idx, end_col]
                                    
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É (–≤ –¥–Ω—è—Ö)
                                    diff_days = (start_date - end_date).days
                                    
                                    # –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –æ—Ç 1 –¥–æ 365 –¥–Ω–µ–π
                                    # ‚Üí —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –æ—à–∏–±–∫–∞ –≤ –≥–æ–¥–µ
                                    if 1 <= diff_days <= 365:
                                        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –≥–æ–¥ —Ñ–∏–Ω–∏—à–∞ = –≥–æ–¥ —Å—Ç–∞—Ä—Ç–∞
                                        corrected_date = end_date.replace(year=start_date.year)
                                        df_clean.at[idx, end_col] = corrected_date
                                        corrected_count += 1
                                        st.info(f"      –°—Ç—Ä–æ–∫–∞ {idx+1}: {end_date.date()} ‚Üí {corrected_date.date()}")
                                
                                if corrected_count > 0:
                                    st.success(f"   ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {corrected_count} –æ—à–∏–±–æ–∫ –≤ –≥–æ–¥–µ")
                                    date_rules_applied += corrected_count
                                    
                    except Exception as e:
                        st.warning(f"   –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ '{start_col}' –∏ '{end_col}': {str(e)[:50]}")
        
        # === –ò–¢–û–ì–ò ===
        if date_rules_applied > 0:
            st.success(f"   ‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ {date_rules_applied} –±–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª –¥–ª—è –¥–∞—Ç")
        else:
            st.info("   ‚ÑπÔ∏è –ë–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –¥–∞—Ç –Ω–µ –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª–∏—Å—å")
        
        # # === –®–ê–ì 7: –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫ '–ü–æ–ª–µ–≤–æ–π' ===
        # st.write("**7Ô∏è‚É£ –î–æ–±–∞–≤–ª—è—é –ø—Ä–∏–∑–Ω–∞–∫ '–ü–æ–ª–µ–≤–æ–π'...**")
        
        # if '–ü–æ–ª–µ–≤–æ–π' not in df_clean.columns:
        #     df_clean['–ü–æ–ª–µ–≤–æ–π'] = 0
        #     st.success("   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–∏–∑–Ω–∞–∫ '–ü–æ–ª–µ–≤–æ–π' = 0 –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π")
        # else:
        #     empty_field = df_clean['–ü–æ–ª–µ–≤–æ–π'].isna().sum()
        #     if empty_field > 0:
        #         df_clean['–ü–æ–ª–µ–≤–æ–π'] = df_clean['–ü–æ–ª–µ–≤–æ–π'].fillna(1)
        #         st.success(f"   ‚úÖ –ó–∞–ø–æ–ª–Ω–µ–Ω–æ {empty_field} –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
        #     else:
        #         st.info("   ‚ÑπÔ∏è –ü—Ä–∏–∑–Ω–∞–∫ '–ü–æ–ª–µ–≤–æ–π' —É–∂–µ –∑–∞–ø–æ–ª–Ω–µ–Ω")
        
        # === –ò–¢–û–ì–ò –û–ß–ò–°–¢–ö–ò ===
        st.markdown("---")
        final_rows = len(df_clean)
        final_cols = len(df_clean.columns)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("–°—Ç—Ä–æ–∫ –¥–æ –æ—á–∏—Å—Ç–∫–∏", original_rows, 
                     delta=f"{final_rows - original_rows}")
        
        with col2:
            st.metric("–°—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ", final_rows)
        
        with col3:
            removed_pct = ((original_rows - final_rows) / original_rows * 100) if original_rows > 0 else 0
            st.metric("–£–¥–∞–ª–µ–Ω–æ", f"{removed_pct:.1f}%")
        
        st.success(f"‚úÖ –ì—É–≥–ª —Ç–∞–±–ª–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω–∞!")
        
        return df_clean

    def clean_array(self, df):
        """–û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–∞ –ú–∞—Å—Å–∏–≤  """
        if df is None or df.empty:
            st.warning("‚ö†Ô∏è –ú–∞—Å—Å–∏–≤ –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
            return None
        
        df_clean = df.copy()
        original_rows = len(df_clean)
        original_cols = len(df_clean.columns)
        
        st.info(f"üßπ –ù–∞—á–∏–Ω–∞—é –æ—á–∏—Å—Ç–∫—É –ú–∞—Å—Å–∏–≤–∞: {original_rows} —Å—Ç—Ä–æ–∫ √ó {original_cols} –∫–æ–ª–æ–Ω–æ–∫")
        
        # === –£–¥–∞–ª–∏—Ç—å –Ω—É–ª–∏ –≤ –¥–∞—Ç–∞—Ö ===
        st.write("**1Ô∏è‚É£ –ó–∞–º–µ–Ω—è—é –Ω—É–ª–∏ –≤ –¥–∞—Ç–∞—Ö –Ω–∞ —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—É—é –¥–∞—Ç—É (1900-01-01)...**")
        
        # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏ –∏–∑ –ú–∞—Å—Å–∏–≤–∞
        DATE_COLUMNS = [
            '–î–∞—Ç–∞ –≤–∏–∑–∏—Ç–∞',
            '–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏', 
            '–î–∞—Ç–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –æ–ø—Ä–æ—Å–∞ –∑–∞ —Ç–∞–π–Ω—ã–º –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–º',
            '–î–∞—Ç–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –æ–ø—Ä–æ—Å–∞ —Ç–∞–π–Ω—ã–º –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–º',
            '–í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è',
            '–í—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–∂–∏–¥–∞–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (–î–∞—Ç–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –æ–ø—Ä–æ—Å–∞?)',
            '–í—Ä–µ–º—è —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è'
        ]
        
        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
        existing_date_cols = [col for col in DATE_COLUMNS if col in df_clean.columns]
        
        if existing_date_cols:
            # –°—É—Ä—Ä–æ–≥–∞—Ç–Ω–∞—è –¥–∞—Ç–∞ –¥–ª—è "—Å–æ–±—ã—Ç–∏–µ –µ—â–µ –Ω–µ –Ω–∞—Å—Ç—É–ø–∏–ª–æ"
            SURROGATE_DATE = pd.Timestamp('1900-01-01')
            
            total_replacements = 0
            
            for col in existing_date_cols:
                try:
                    # üî¥ –£–ü–†–û–©–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê:
                    # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –í–°–ï –∑–Ω–∞—á–µ–Ω–∏—è –≤ datetime
                    df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce', dayfirst=True)
                    
                    # 2. –ù–∞—Ö–æ–¥–∏–º NaT (–Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞—Ç—ã)
                    nat_mask = df_clean[col].isna()
                    
                    # 3. –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ NaT –Ω–∞ —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—É—é –¥–∞—Ç—É
                    if nat_mask.any():
                        df_clean.loc[nat_mask, col] = SURROGATE_DATE
                        col_replacements = nat_mask.sum()
                        total_replacements += col_replacements
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π
                        example_indices = nat_mask[nat_mask].index[:3]
                        if len(example_indices) > 0:
                            st.info(f"   '{col}': –∑–∞–º–µ–Ω–µ–Ω–æ {col_replacements} –∑–Ω–∞—á–µ–Ω–∏–π")
                            for idx in example_indices:
                                if idx < len(df):  
                                    orig_val = df.at[idx, col]  
                                    st.info(f"     –°—Ç—Ä–æ–∫–∞ {idx}: '{orig_val}' ‚Üí '{SURROGATE_DATE.date()}'")
                                
                except Exception as e:
                    st.warning(f"   –û—à–∏–±–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ '{col}': {str(e)[:100]}")
            
            if total_replacements > 0:
                st.success(f"   ‚úÖ –ó–∞–º–µ–Ω–µ–Ω–æ {total_replacements} –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç –Ω–∞ {SURROGATE_DATE.date()}")
                st.info("   **–û–±–æ–∑–Ω–∞—á–∞–µ—Ç:** '–°–æ–±—ã—Ç–∏–µ –µ—â–µ –Ω–µ –Ω–∞—Å—Ç—É–ø–∏–ª–æ'")
            else:
                st.info("   ‚ÑπÔ∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        else:
            st.warning(f"   ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏")
            st.info(f"   –ò—Å–∫–∞–ª: {', '.join(DATE_COLUMNS[:3])}...")
        
        # === –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–∞—Å—Å–∏–≤ –Ω–∞ –ù/–î ===
        st.write("**2Ô∏è‚É£ –ó–∞–º–µ–Ω—è—é –ù/–î –Ω–∞ –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è...**")
        
        # –ó–Ω–∞—á–µ–Ω–∏—è –ù/–î –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å
        na_values = ['–ù/–î', '–Ω/–¥', 'N/A', 'n/a', '#–ù/–î', '#–Ω/–¥', 'NA', 'na', '-', '‚Äî', '‚Äì']
        
        na_replacements = 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –í–°–ï –∫–æ–ª–æ–Ω–∫–∏ (–Ω–µ —Ç–æ–ª—å–∫–æ –¥–∞—Ç—ã)
        for col in df_clean.columns:
            try:
                # –ó–∞–º–µ–Ω—è–µ–º –∫–∞–∂–¥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ù/–î
                for na_val in na_values:
                    mask = df_clean[col].astype(str).str.strip() == na_val
                    if mask.any():
                        df_clean.loc[mask, col] = ''
                        na_replacements += mask.sum()
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –∑–∞–º–µ–Ω—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ 'nan', 'NaN'
                nan_mask = df_clean[col].astype(str).str.strip().str.lower().isin(['nan', 'none', 'null'])
                if nan_mask.any():
                    df_clean.loc[nan_mask, col] = ''
                    na_replacements += nan_mask.sum()
                    
            except Exception as e:
                st.warning(f"   –û—à–∏–±–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ '{col}': {str(e)[:50]}")
        
        if na_replacements > 0:
            st.success(f"   ‚úÖ –ó–∞–º–µ–Ω–µ–Ω–æ {na_replacements} –∑–Ω–∞—á–µ–Ω–∏–π –ù/–î")
        else:
            st.info("   ‚ÑπÔ∏è –ó–Ω–∞—á–µ–Ω–∏–π –ù/–î –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        # === –®–ê–ì 8: –î–æ–±–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É –ó–û–î ===
        st.write("**3Ô∏è‚É£ –î–æ–±–∞–≤–ª—è—é –∫–æ–ª–æ–Ω–∫—É –ó–û–î (–ø–æ–∫–∞ –ø—É—Å—Ç—É—é)...**")
        
        if '–ó–û–î' not in df_clean.columns:
            df_clean['–ó–û–î'] = ''
            st.success("   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '–ó–û–î' (–±—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–∞ –ø–æ–∑–∂–µ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞)")
        else:
            st.info("   ‚ÑπÔ∏è –ö–æ–ª–æ–Ω–∫–∞ '–ó–û–î' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        
        # === –ò–¢–û–ì–ò –û–ß–ò–°–¢–ö–ò ===
        st.markdown("---")
        st.success(f"‚úÖ –ú–∞—Å—Å–∏–≤ —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω!")

        # === –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–æ–∫–∞—Ö —Å –ù/–î –¥–ª—è –æ—Ç—á–µ—Ç–∞ ===
        st.write("**4Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω—è—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–æ–∫–∞—Ö —Å –ù/–î –¥–ª—è –æ—Ç—á–µ—Ç–∞...**")
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —Å—Ç—Ä–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ–ª–∏ –ù/–î
        had_na_mask = pd.Series(False, index=df_clean.index)
        
        for col in df_clean.columns:
            try:
                # –ò—â–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ù/–î
                for na_val in na_values:
                    mask = df[col].astype(str).str.strip() == na_val
                    had_na_mask = had_na_mask | mask
            except:
                continue
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞—Å–∫—É –∫–∞–∫ –∞—Ç—Ä–∏–±—É—Ç DataFrame
        df_clean.attrs['had_na_rows'] = had_na_mask
        df_clean.attrs['na_rows_count'] = had_na_mask.sum()
        
        st.success(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {had_na_mask.sum()} —Å—Ç—Ä–æ–∫ —Å –ù/–î –¥–ª—è –æ—Ç—á–µ—Ç–∞")
        
        return df_clean
    
    def add_zod_from_hierarchy(self, array_df, hierarchy_df):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–ª–æ–Ω–∫—É –ó–û–î –≤ –º–∞—Å—Å–∏–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –ó–û–î+–ê–°–°
        –õ–æ–≥–∏–∫–∞: –ê–°–° (–º–∞—Å—Å–∏–≤) -> –ó–û–î (—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫)
        """
        try:
            if array_df is None or array_df.empty:
                return array_df
                
            if hierarchy_df is None or hierarchy_df.empty:
                st.warning("‚ö†Ô∏è –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ó–û–î+–ê–°–° –ø—É—Å—Ç–æ–π")
                return array_df
            
            array_clean = array_df.copy()
            hierarchy_clean = hierarchy_df.copy()
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫–∏ –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ
            zodiac_col = self._find_column(hierarchy_clean, ['–ó–û–î', 'zod', 'ZOD'])
            acc_col = self._find_column(hierarchy_clean, ['–ê–°–°', 'acc', 'ACC'])
            
            if not zodiac_col or not acc_col:
                st.error("‚ùå –í —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ –ó–û–î –∏/–∏–ª–∏ –ê–°–°")
                return array_df
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫—É –ê–°–° –≤ –º–∞—Å—Å–∏–≤–µ
            array_acc_col = self._find_column(array_clean, ['–ê–°–°', 'acc', 'ACC'])
            
            if not array_acc_col:
                st.error("‚ùå –í –º–∞—Å—Å–∏–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ –ê–°–°")
                return array_df
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è {–ê–°–°: –ó–û–î}
            zod_mapping = {}
            for _, row in hierarchy_clean.iterrows():
                acc_val = str(row[acc_col]).strip()
                zod_val = str(row[zodiac_col]).strip()
                
                if acc_val and acc_val.lower() not in ['nan', 'none', 'null', '']:
                    zod_mapping[acc_val] = zod_val
            
            st.info(f"üîç –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(zod_mapping)} —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π –ê–°–° ‚Üí –ó–û–î")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É –ó–û–î
            if '–ó–û–î' in array_clean.columns:
                array_clean['–ó–û–î'] = ''
            else:
                array_clean['–ó–û–î'] = ''
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ó–û–î –Ω–∞ –æ—Å–Ω–æ–≤–µ –ê–°–°
            def get_zod_by_acc(acc_value):
                if pd.isna(acc_value) or str(acc_value).strip().lower() in ['nan', 'none', 'null', '']:
                    return ''
                clean_acc = str(acc_value).strip()
                return zod_mapping.get(clean_acc, '')
            
            array_clean['–ó–û–î'] = array_clean[array_acc_col].apply(get_zod_by_acc)
            
            filled_count = (array_clean['–ó–û–î'] != '').sum()
            st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –ó–û–î: –∑–∞–ø–æ–ª–Ω–µ–Ω–æ {filled_count} –∑–Ω–∞—á–µ–Ω–∏–π")
            
            return array_clean
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ add_zod_from_hierarchy: {str(e)[:100]}")
            return array_df

    def export_array_to_excel(self, cleaned_array_df, filename="–æ—á–∏—â–µ–Ω–Ω—ã–π_–º–∞—Å—Å–∏–≤"):
        """
        –°–æ–∑–¥–∞–µ—Ç Excel —Ñ–∞–π–ª –¥–ª—è –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞:
        - –í–∫–ª–∞–¥–∫–∞ 1: –û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        try:
            if cleaned_array_df is None or cleaned_array_df.empty:
                return None
            
            output = io.BytesIO()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä pd.ExcelWriter
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # === –í–ö–õ–ê–î–ö–ê 1: –û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ===
                cleaned_array_df.to_excel(
                    writer, 
                    sheet_name='–û–ß–ò–©–ï–ù–ù–´–ô –ú–ê–°–°–ò–í', 
                    index=False
                )
            
            # –í–∞–∂–Ω–æ: –ø–µ—Ä–µ–º–µ—â–∞–µ–º —É–∫–∞–∑–∞—Ç–µ–ª—å –≤ –Ω–∞—á–∞–ª–æ
            output.seek(0)
            return output
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel: {e}")
            return None

        
    def enrich_array_with_project_codes(self, cleaned_array_df, projects_df):
        """
        –ò—â–µ—Ç –∏ –∑–∞–ø–æ–ª–Ω—è–µ—Ç –ø—É—Å—Ç—ã–µ '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã' –≤ –æ—á–∏—â–µ–Ω–Ω–æ–º –ú–∞—Å—Å–∏–≤–µ,
        –∏—Å–ø–æ–ª—å–∑—É—è –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –ü—Ä–æ–µ–∫—Ç–æ–≤ –°–µ—Ä–≤–∏–∑–æ—Ä–∏—è.
    
        –õ–æ–≥–∏–∫–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:
        - '–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞' (–ú–∞—Å—Å–∏–≤) -> '–ü—Ä–æ–µ–∫—Ç—ã –≤  https://ru.checker-soft.com' (–ü—Ä–æ–µ–∫—Ç—ã)
        - '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞' (–ú–∞—Å—Å–∏–≤) -> '–ù–∞–∑–≤–∞–Ω–∏–µ –≤–æ–ª–Ω—ã –Ω–∞ –ß–µ–∫–µ—Ä–µ/–∏–Ω–æ–º –ü–û' (–ü—Ä–æ–µ–∫—Ç—ã)
        """
        array_df = cleaned_array_df.copy()

        
        # ============================================
        # –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•
        # ============================================
        st.write("\n**4. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•:**")
        
        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        projects_df = projects_df.copy()
        
        # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã'
        empty_code_mask = (
            array_df['–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã'].isna() |
            (array_df['–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã'].astype(str).str.strip() == '')
        )
        rows_to_process = array_df[empty_code_mask]
        total_empty = len(rows_to_process)
        
        st.write(f"- –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã': {total_empty}/{len(array_df)}")
        
        if total_empty == 0:
            st.success("‚úÖ –ù–µ—á–µ–≥–æ –∑–∞–ø–æ–ª–Ω—è—Ç—å. –í—Å–µ –∫–æ–¥—ã –∞–Ω–∫–µ—Ç—ã —É–∂–µ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã.")
            return array_df, pd.DataFrame(), {'processed': 0, 'filled': 0, 'discrepancies': 0}
        
        # ============================================
        # –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ –ü–û–ò–°–ö–ê
        # ============================================
        st.write("\n**5. –ü–û–ò–°–ö –°–û–í–ü–ê–î–ï–ù–ò–ô:**")
        st.write(f"- –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {total_empty} —Å—Ç—Ä–æ–∫...")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        projects_df['_match_client'] = projects_df['–ü—Ä–æ–µ–∫—Ç—ã –≤  https://ru.checker-soft.com'].astype(str).str.strip()
        projects_df['_match_wave'] = projects_df['–ù–∞–∑–≤–∞–Ω–∏–µ –≤–æ–ª–Ω—ã –Ω–∞ –ß–µ–∫–µ—Ä–µ/–∏–Ω–æ–º –ü–û'].astype(str).str.strip()
        
        # –°—á–µ—Ç—á–∏–∫–∏
        filled_count = 0
        discrepancy_rows = []
        match_stats = {
            'client_match': 0,  # —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–ª–∏–µ–Ω—Ç—É
            'wave_match': 0,    # —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –≤–æ–ª–Ω–µ
            'both_match': 0,    # —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –æ–±–æ–∏–º –ø–æ–ª—è–º
            'code_empty': 0,    # –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ –ø—É—Å—Ç–æ–π
            'no_match': 0       # –Ω–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        }
        
        # –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        examples = []
        
        for idx, row in rows_to_process.iterrows():
            client_name = str(row['–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞']).strip() if pd.notna(row['–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞']) else ''
            project_name = str(row['–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞']).strip() if pd.notna(row['–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞']) else ''
            
            # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            match_mask = (
                (projects_df['_match_client'] == client_name) &
                (projects_df['_match_wave'] == project_name)
            )
            
            matched_rows = projects_df[match_mask]
            
            if not matched_rows.empty:
                match_stats['both_match'] += 1
                project_code = matched_rows.iloc[0]['–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ RU00.000.00.01SVZ24']
                
                if pd.notna(project_code) and str(project_code).strip() != '':
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –∫–æ–¥
                    array_df.at[idx, '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã'] = str(project_code).strip()
                    filled_count += 1
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–ø–µ—Ä–≤—ã–µ 3)
                    if len(examples) < 3:
                        examples.append({
                            '–∫–ª–∏–µ–Ω—Ç': client_name[:30] + '...' if len(client_name) > 30 else client_name,
                            '–ø—Ä–æ–µ–∫—Ç': project_name[:30] + '...' if len(project_name) > 30 else project_name,
                            '–Ω–∞–π–¥–µ–Ω–Ω—ã–π –∫–æ–¥': str(project_code).strip()[:20] + '...' if len(str(project_code)) > 20 else str(project_code)
                        })
                else:
                    match_stats['code_empty'] += 1
                    discrepancy_rows.append(row.to_dict())
            else:
                match_stats['no_match'] += 1
                discrepancy_rows.append(row.to_dict())
        
        # ============================================
        # –†–ï–ó–£–õ–¨–¢–ê–¢–´
        # ============================================
        st.write("\n**6. –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê:**")
        st.write(f"- –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –æ–±–æ–∏–º –ø–æ–ª—è–º (–∫–ª–∏–µ–Ω—Ç+–≤–æ–ª–Ω–∞): {match_stats['both_match']}/{total_empty}")
        st.write(f"- –ò–∑ –Ω–∏—Ö —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º –∫–æ–¥–æ–º –ø—Ä–æ–µ–∫—Ç–∞: {filled_count}/{match_stats['both_match']}")
        st.write(f"- –ò–∑ –Ω–∏—Ö —Å –ø—É—Å—Ç—ã–º –∫–æ–¥–æ–º –ø—Ä–æ–µ–∫—Ç–∞: {match_stats['code_empty']}/{match_stats['both_match']}")
        st.write(f"- –ë–µ–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {match_stats['no_match']}/{total_empty}")
        
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        discrepancy_df = pd.DataFrame(discrepancy_rows) if discrepancy_rows else pd.DataFrame()
        
        st.write("\n**7. –ò–¢–û–ì–ò:**")
        st.write(f"- –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_empty} —Å—Ç—Ä–æ–∫")
        st.write(f"- –£—Å–ø–µ—à–Ω–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ: {filled_count} –∫–æ–¥–æ–≤")
        st.write(f"- –û—Å—Ç–∞–ª–æ—Å—å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π: {len(discrepancy_df)} —Å—Ç—Ä–æ–∫")
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        projects_df.drop(['_match_client', '_match_wave'], axis=1, inplace=True, errors='ignore')
        
        st.success(f"‚úÖ –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        st.write("=" * 50)
        
        stats = {
            'processed': total_empty,
            'filled': filled_count,
            'discrepancies': len(discrepancy_df),
            'match_stats': match_stats
        }
        
        return array_df, discrepancy_df, stats


    def export_discrepancies_to_excel(self, discrepancy_df, filename="–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ_–ú–∞—Å—Å–∏–≤"):
        try:
            if discrepancy_df is None or discrepancy_df.empty:
                return None
            
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—É—é –≤–∫–ª–∞–¥–∫—É
                info_df = pd.DataFrame({
                    '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è': [
                        '–§–∞–π–ª —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏',
                        f'–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {pd.Timestamp.now().strftime("%Y-%m-%d %H:%M")}',
                        f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(discrepancy_df)}',
                        '–≠—Ç–∏ —Å—Ç—Ä–æ–∫–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–æ–≥–∞—Ç–∏—Ç—å –∫–æ–¥–∞–º–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤'
                    ]
                })
                info_df.to_excel(writer, sheet_name='–ò–ù–§–û', index=False)
                
                # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                discrepancy_df.to_excel(writer, sheet_name='–†–ê–°–•–û–ñ–î–ï–ù–ò–Ø', index=False)
            
            output.seek(0)
            return output
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel —Å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è–º–∏: {e}")
            return None

    
    
    def export_to_excel(self, df, cleaned_df, filename="–æ—á–∏—â–µ–Ω–Ω—ã–µ_–¥–∞–Ω–Ω—ã–µ"):
        try:
            if df is None or cleaned_df is None:
                return None
            
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # –í–∫–ª–∞–¥–∫–∞ 1: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                df.to_excel(writer, sheet_name='–û–†–ò–ì–ò–ù–ê–õ', index=False)
                
                # –í–∫–ª–∞–¥–∫–∞ 2: –û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                cleaned_df.to_excel(writer, sheet_name='–û–ß–ò–©–ï–ù–ù–´–ô', index=False)
            
            output.seek(0)
            return output
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel: {e}")
            return None
    
    # ============================================
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ú–∞—Å—Å–∏–≤–∞ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    # ============================================
    
    def update_field_projects_flag(self, google_df):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ–ª–µ '–ü–æ–ª–µ–≤–æ–π' –≤ –≥—É–≥–ª —Ç–∞–±–ª–∏—Ü–µ
        –ü–æ–ª–µ–≤–æ–π = 1 –µ—Å–ª–∏:
        1. –°—Ç—Ä–∞–Ω–∞ = RU00 –ò –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ = .01/.02
        2. –ò–ª–∏ –∫–æ–¥ —Å–æ–¥–µ—Ä–∂–∏—Ç: –º—É–ª—å—Ç–∏–∫–æ–¥/–ø–∏–ª–æ—Ç/—Å–µ–º–ø–ª (–ª—é–±–æ–π —Ä–µ–≥–∏—Å—Ç—Ä)
        """
        try:
            google_df = google_df.copy()
            
            # –ö–æ–ª–æ–Ω–∫–∞ —Å –∫–æ–¥–æ–º –ø—Ä–æ–µ–∫—Ç–∞
            code_col = '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ RU00.000.00.01SVZ24'
            
            if code_col not in google_df.columns:
                return google_df
            
            def is_field_project(code):
                try:
                    if pd.isna(code):
                        return 0
                        
                    code_str = str(code).strip()
                    lower_code = code_str.lower()
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º—É–ª—å—Ç–∏–∫–æ–¥/–ø–∏–ª–æ—Ç/—Å–µ–º–ø–ª
                    if any(word in lower_code for word in ['–º—É–ª—å—Ç–∏–∫–æ–¥', '–ø–∏–ª–æ—Ç', '—Å–µ–º–ø–ª']):
                        return 1
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ RU00.001.06.01SVZ24
                    parts = code_str.split('.')
                    if len(parts) >= 4:
                        country = parts[0]  # RU00
                        direction = parts[2][:3] if len(parts[2]) >= 3 else ''  # .01 –∏–ª–∏ .02
                        
                        if country == 'RU00' and direction in ['.01', '.02']:
                            return 1
                            
                    return 0
                except:
                    return 0
            
            google_df['–ü–æ–ª–µ–≤–æ–π'] = google_df[code_col].apply(is_field_project)
            
            field_count = google_df['–ü–æ–ª–µ–≤–æ–π'].sum()
            st.info(f"üîç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ {field_count} –ø–æ–ª–µ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤")
            
            return google_df
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –≤ update_field_projects_flag: {e}")
            return google_df


    def add_field_flag_to_array(self, array_df):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç '–ü–æ–ª–µ–≤–æ–π' –≤ –º–∞—Å—Å–∏–≤
        –ü–æ–ª–µ–≤–æ–π = 1 –µ—Å–ª–∏:
        1. –°—Ç—Ä–∞–Ω–∞ = RU00 –ò –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ = .01/.02
        2. –ò–ª–∏ –∫–æ–¥ —Å–æ–¥–µ—Ä–∂–∏—Ç: –º—É–ª—å—Ç–∏–∫–æ–¥/–ø–∏–ª–æ—Ç/—Å–µ–º–ø–ª (–ª—é–±–æ–π —Ä–µ–≥–∏—Å—Ç—Ä)
        """
        try:
            array_df = array_df.copy()
            
            # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –∫–æ–¥–æ–º –∞–Ω–∫–µ—Ç—ã
            code_col = None
            for col in array_df.columns:
                if '–∫–æ–¥' in str(col).lower() and '–∞–Ω–∫–µ—Ç' in str(col).lower():
                    code_col = col
                    break
            
            if not code_col:
                st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã'")
                return array_df
            
            def is_field_project(code):
                try:
                    if pd.isna(code):
                        return 0
                        
                    code_str = str(code).strip()
                    lower_code = code_str.lower()
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º—É–ª—å—Ç–∏–∫–æ–¥/–ø–∏–ª–æ—Ç/—Å–µ–º–ø–ª
                    if any(word in lower_code for word in ['–º—É–ª—å—Ç–∏–∫–æ–¥', '–ø–∏–ª–æ—Ç', '—Å–µ–º–ø–ª']):
                        return 1
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ RU00.001.06.01SVZ24
                    parts = code_str.split('.')
                    if len(parts) >= 4:
                        country = parts[0]  # RU00
                        direction = parts[2][:3] if len(parts[2]) >= 3 else ''  # .01 –∏–ª–∏ .02
                        
                        if country == 'RU00' and direction in ['.01', '.02']:
                            return 1
                            
                    return 0
                except:
                    return 0
            
            array_df['–ü–æ–ª–µ–≤–æ–π'] = array_df[code_col].apply(is_field_project)
            
            field_count = array_df['–ü–æ–ª–µ–≤–æ–π'].sum()
            st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω '–ü–æ–ª–µ–≤–æ–π': {field_count} –ø–æ–ª–µ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")
            
            return array_df
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –≤ add_field_flag_to_array: {e}")
            return array_df
    
    def split_array_by_field_flag(self, array_df):
        """
        –†–∞–∑–¥–µ–ª—è–µ—Ç –º–∞—Å—Å–∏–≤ –Ω–∞ –ü–æ–ª–µ–≤—ã–µ –∏ –ù–µ–ø–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–ª–æ–Ω–∫—É '–ü–æ–ª–µ–≤–æ–π' –≤ –æ–±–µ–∏—Ö —á–∞—Å—Ç—è—Ö
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 9 –∫–æ–ª–æ–Ω–æ–∫ (8 –æ—Å–Ω–æ–≤–Ω—ã—Ö + –ü–æ–ª–µ–≤–æ–π)
        """
        try:
            if array_df is None or array_df.empty:
                st.warning("‚ö†Ô∏è –ú–∞—Å—Å–∏–≤ –ø—É—Å—Ç–æ–π")
                return None, None
            
            array_df_clean = array_df.copy()
            
            if '–ü–æ–ª–µ–≤–æ–π' not in array_df_clean.columns:
                st.error("‚ùå –í –º–∞—Å—Å–∏–≤–µ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ü–æ–ª–µ–≤–æ–π'")
                return None, None
            
            # –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (9 –∫–æ–ª–æ–Ω–æ–∫)
            column_mapping = {
                '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞': ['–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã'],
                '–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞': ['–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞'],
                '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞': ['–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞'],
                '–ó–û–î': ['–ó–û–î', 'ZOD', '–ó–æ–¥', 'zod'],
                '–ê–°–°': ['–ê–°–°', 'ASS', '–ê—Å—Å', 'ass'],
                '–≠–ú': ['–≠–ú —Ä–µ–≥'],
                '–†–µ–≥–∏–æ–Ω short': ['–†–µ–≥–∏–æ–Ω'],
                '–†–µ–≥–∏–æ–Ω': ['–†–µ–≥–∏–æ–Ω '],
                '–ü–æ–ª–µ–≤–æ–π': ['–ü–æ–ª–µ–≤–æ–π']  # –°–û–•–†–ê–ù–Ø–ï–ú
            }
            
            # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
            actual_columns = {}
            
            for std_col, possible_names in column_mapping.items():
                found_col = self._find_column(array_df_clean, possible_names)
                if found_col:
                    actual_columns[std_col] = found_col
                else:
                    # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é –∫–æ–ª–æ–Ω–∫—É (–∫—Ä–æ–º–µ –ü–æ–ª–µ–≤–æ–π)
                    if std_col != '–ü–æ–ª–µ–≤–æ–π':
                        array_df_clean[std_col] = ''
                        actual_columns[std_col] = std_col
            
            # –û—Ç–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            selected_cols = list(actual_columns.values())
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            field_mask = array_df_clean['–ü–æ–ª–µ–≤–æ–π'] == 1
            field_projects = array_df_clean.loc[field_mask, selected_cols].copy()
            non_field_projects = array_df_clean.loc[~field_mask, selected_cols].copy()
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏
            reverse_mapping = {v: k for k, v in actual_columns.items()}
            
            if not field_projects.empty:
                field_projects = field_projects.rename(columns=reverse_mapping)
            
            if not non_field_projects.empty:
                non_field_projects = non_field_projects.rename(columns=reverse_mapping)
            
            # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
            final_columns = ['–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞', '–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞', '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 
                           '–ó–û–î', '–ê–°–°', '–≠–ú', '–†–µ–≥–∏–æ–Ω short', '–†–µ–≥–∏–æ–Ω', '–ü–æ–ª–µ–≤–æ–π']
            
            # –†–µ–æ—Ä–≥–∞–Ω–∏–∑—É–µ–º –∫–æ–ª–æ–Ω–∫–∏
            if not field_projects.empty:
                for col in final_columns:
                    if col not in field_projects.columns:
                        field_projects[col] = '' if col != '–ü–æ–ª–µ–≤–æ–π' else 0
                field_projects = field_projects.reindex(columns=final_columns)
            
            if not non_field_projects.empty:
                for col in final_columns:
                    if col not in non_field_projects.columns:
                        non_field_projects[col] = '' if col != '–ü–æ–ª–µ–≤–æ–π' else 0
                non_field_projects = non_field_projects.reindex(columns=final_columns)
            
            st.success(f"‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:")
            st.info(f"   üìä –ü–æ–ª–µ–≤—ã–µ: {len(field_projects)} –∑–∞–ø–∏—Å–µ–π")
            st.info(f"   üìä –ù–µ–ø–æ–ª–µ–≤—ã–µ: {len(non_field_projects)} –∑–∞–ø–∏—Å–µ–π")
            
            return field_projects, non_field_projects
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ split_array_by_field_flag: {str(e)[:100]}")
            return None, None
    
    
    def export_split_array_to_excel(self, field_df, non_field_df, filename="—Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–π_–º–∞—Å—Å–∏–≤"):
        """ –°–æ–∑–¥–∞–µ—Ç Excel —Å –≤–∫–ª–∞–¥–∫–∞–º–∏ –ü–æ–ª–µ–≤—ã–µ/–ù–µ–ø–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã """
        try:
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # –ü–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
                if field_df is not None and not field_df.empty:
                    field_df.to_excel(writer, sheet_name='–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False)
                else:
                    pd.DataFrame({'–°–æ–æ–±—â–µ–Ω–∏–µ': ['–ù–µ—Ç –ø–æ–ª–µ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤']}).to_excel(
                        writer, sheet_name='–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False
                    )
                
                # –ù–µ–ø–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
                if non_field_df is not None and not non_field_df.empty:
                    non_field_df.to_excel(writer, sheet_name='–ù–ï–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False)
                else:
                    pd.DataFrame({'–°–æ–æ–±—â–µ–Ω–∏–µ': ['–ù–µ—Ç –Ω–µ–ø–æ–ª–µ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤']}).to_excel(
                        writer, sheet_name='–ù–ï–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False
                    )
                
                # # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                # stats_data = {
                #     '–ú–µ—Ç—Ä–∏–∫–∞': ['–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π', '–ü–æ–ª–µ–≤—ã–µ', '–ù–µ–ø–æ–ª–µ–≤—ã–µ', '–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏'],
                #     '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                #         (len(field_df) if field_df is not None else 0) + 
                #         (len(non_field_df) if non_field_df is not None else 0),
                #         len(field_df) if field_df is not None else 0,
                #         len(non_field_df) if non_field_df is not None else 0,
                #         pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                #     ]
                # }
                # pd.DataFrame(stats_data).to_excel(writer, sheet_name='–°–¢–ê–¢–ò–°–¢–ò–ö–ê', index=False)
            
            output.seek(0)
            return output
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel: {str(e)[:100]}")
            return None
            
    def export_field_projects_only(self, field_df, filename="–ø–æ–ª–µ–≤—ã–µ_–ø—Ä–æ–µ–∫—Ç—ã"):
        """
        –°–æ–∑–¥–∞–µ—Ç Excel —Ñ–∞–π–ª –¢–û–õ–¨–ö–û —Å –ø–æ–ª–µ–≤—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞–º–∏
        """
        try:
            if field_df is None or field_df.empty:
                return None
            
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # –ü–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
                if not field_df.empty:
                    field_df.to_excel(writer, sheet_name='–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False)
                else:
                    pd.DataFrame({'–°–æ–æ–±—â–µ–Ω–∏–µ': ['–ù–µ—Ç –ø–æ–ª–µ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤']}).to_excel(
                        writer, sheet_name='–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False
                    )
            
            output.seek(0)
            return output
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel (–ø–æ–ª–µ–≤—ã–µ): {str(e)[:100]}")
            return None

    def export_non_field_projects_only(self, non_field_df, filename="–Ω–µ–ø–æ–ª–µ–≤—ã–µ_–ø—Ä–æ–µ–∫—Ç—ã"):
        """
        –°–æ–∑–¥–∞–µ—Ç Excel —Ñ–∞–π–ª –¢–û–õ–¨–ö–û —Å –Ω–µ–ø–æ–ª–µ–≤—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞–º–∏
        –£–î–ê–õ–Ø–ï–¢ –î–£–ë–õ–ò–ö–ê–¢–´ –ø–æ: –ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞, –ò–º—è –∫–ª–∏–µ–Ω—Ç–∞, –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
        """
        try:
            if non_field_df is None or non_field_df.empty:
                return None
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ 3 –ø–æ–ª—è–º
            non_field_clean = non_field_df.copy()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            required_cols = ['–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞', '–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞', '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞']
            missing_cols = [col for col in required_cols if col not in non_field_clean.columns]
            
            if missing_cols:
                st.warning(f"‚ö†Ô∏è –í –Ω–µ–ø–æ–ª–µ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: {missing_cols}")
                # –ï—Å–ª–∏ –Ω–µ—Ç –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ - –Ω–µ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                non_field_unique = non_field_clean
                duplicates_removed = 0
            else:
                # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                before_rows = len(non_field_clean)
                non_field_unique = non_field_clean.drop_duplicates(
                    subset=required_cols, 
                    keep='first'
                )
                after_rows = len(non_field_unique)
                duplicates_removed = before_rows - after_rows
            
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # –ù–µ–ø–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã (–±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
                if not non_field_unique.empty:
                    # –£–î–ê–õ–Ø–ï–ú –õ–ò–®–ù–ò–ï –ö–û–õ–û–ù–ö–ò
                    columns_to_drop = ['–ó–û–î', '–ê–°–°', '–≠–ú', '–†–µ–≥–∏–æ–Ω short', '–†–µ–≥–∏–æ–Ω', '–ü–æ–ª–µ–≤–æ–π']
                    columns_exist = [col for col in columns_to_drop if col in non_field_unique.columns]
                    
                    if columns_exist:
                        non_field_clean = non_field_unique.drop(columns=columns_exist, errors='ignore')
                    else:
                        non_field_clean = non_field_unique
                        
                    non_field_clean.to_excel(writer, sheet_name='–ù–ï–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—É—é –≤–∫–ª–∞–¥–∫—É
                    info_data = {
                        '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è': [
                            f'–§–∞–π–ª —Å–æ–∑–¥–∞–Ω: {pd.Timestamp.now().strftime("%Y-%m-%d %H:%M")}',
                            f'–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–æ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {before_rows}',
                            f'–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è: {after_rows}',
                            f'–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_removed}',
                            f'–ü–æ–ª—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: –ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞, –ò–º—è –∫–ª–∏–µ–Ω—Ç–∞, –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞'
                        ]
                    }
                    pd.DataFrame(info_data).to_excel(writer, sheet_name='–ò–ù–§–û–†–ú–ê–¶–ò–Ø', index=False)
                else:
                    pd.DataFrame({'–°–æ–æ–±—â–µ–Ω–∏–µ': ['–ù–µ—Ç –Ω–µ–ø–æ–ª–µ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤']}).to_excel(
                        writer, sheet_name='–ù–ï–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False
                    )
            
            output.seek(0)
            return output
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel (–Ω–µ–ø–æ–ª–µ–≤—ã–µ): {str(e)[:100]}")
            return None

    def check_problematic_projects(self, google_df, autocoding_df, array_df):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
        result = google_df.copy()
        
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        code_col = '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ RU00.000.00.01SVZ24'
        project_col = '–ü—Ä–æ–µ–∫—Ç—ã –≤  https://ru.checker-soft.com'
        wave_col = '–ù–∞–∑–≤–∞–Ω–∏–µ –≤–æ–ª–Ω—ã –Ω–∞ –ß–µ–∫–µ—Ä–µ/–∏–Ω–æ–º –ü–û'
        portal_col = '–ü–æ—Ä—Ç–∞–ª –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –∏–¥–µ—Ç –ø—Ä–æ–µ–∫—Ç (–¥–ª—è —Ä–∞–±–æ—Ç—ã –ø–æ–ª–µ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã)'

        # 1. –ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ –ø—É—Å—Ç–æ
        result['–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ –ø—É—Å—Ç–æ'] = (
            result[code_col].isna() |                     # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π pandas NaN
            (result[code_col].astype(str).str.strip() == 'nan') |   # —Ç–µ–∫—Å—Ç–æ–≤—ã–π 'nan'
            (result[code_col].astype(str).str.strip() == 'NaN') |   # —Ç–µ–∫—Å—Ç–æ–≤—ã–π 'NaN' (–∑–∞–≥–ª–∞–≤–Ω—ã–µ)
            (result[code_col].astype(str).str.strip() == 'None') |  # —Ç–µ–∫—Å—Ç–æ–≤—ã–π 'None'
            (result[code_col].astype(str).str.strip() == 'null') |  # —Ç–µ–∫—Å—Ç–æ–≤—ã–π 'null'
            (result[code_col].astype(str).str.strip() == '')        # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        )
        
        # 2. –ü—Ä–æ–µ–∫—Ç–∞ –Ω–µ—Ç –≤ –∞–≤—Ç–æ–∫–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if autocoding_df is not None:
            ak_code_col = '–ò–¢–û–ì–û –ö–û–î'
            ak_project_col = '–ü—Ä–æ–µ–∫—Ç—ã –≤  https://ru.checker-soft.com'

            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            # –¢–û–õ–¨–ö–û –Ω–µ–ø—É—Å—Ç—ã–µ –ø–∞—Ä—ã –∏–∑ –ê–ö
            ak_valid_mask = autocoding_df[ak_code_col].notna() & autocoding_df[ak_project_col].notna()
            ak_keys = set(zip(
                autocoding_df.loc[ak_valid_mask, ak_code_col].astype(str).str.strip(),
                autocoding_df.loc[ak_valid_mask, ak_project_col].astype(str).str.strip()
            ))
       
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–∞—Ä (–∫–æ–¥ + –ø—Ä–æ–µ–∫—Ç)
            valid_mask = result[code_col].notna() & result[project_col].notna()
            valid_keys = list(zip(
                result.loc[valid_mask, code_col].astype(str).str.strip(),
                result.loc[valid_mask, project_col].astype(str).str.strip()
            ))
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∫–∞–∫ True
            result['–ü—Ä–æ–µ–∫—Ç–∞ –ù–ï–¢ –≤ –ê–ö'] = True
            # –î–ª—è –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –ø—Ä–æ–≤–µ—Ä—è–µ–º
            if valid_mask.any():
                # key in ak_keys ‚Üí –Ω–∞–π–¥–µ–Ω ‚Üí –º–µ–Ω—è–µ–º –Ω–∞ False
                found_mask = [key in ak_keys for key in valid_keys]
                result.loc[valid_mask, '–ü—Ä–æ–µ–∫—Ç–∞ –ù–ï–¢ –≤ –ê–ö'] = [not found for found in found_mask]
            
        else:
            result['–ü—Ä–æ–µ–∫—Ç–∞ –ù–ï–¢ –≤ –ê–ö'] = True
        
        # 3. –ü—Ä–æ–µ–∫—Ç –µ—Å—Ç—å –≤ –º–∞—Å—Å–∏–≤–µ, –Ω–æ –Ω–µ –ø–æ–ª–µ–≤–æ–π (–µ—Å—Ç—å –≤ –º–∞—Å—Å–∏–≤–µ –∏ –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ –Ω–µ–ø–æ–ª–µ–≤–æ–π)
        if array_df is not None:
            array_code_col = '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã'
            array_project_col = '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞'
            
            # –í—Å–µ –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ –º–∞—Å—Å–∏–≤–∞
            all_array_keys = set(zip(
                array_df[array_code_col].astype(str).str.strip().fillna(''),
                array_df[array_project_col].astype(str).str.strip().fillna('')
            ))
            
            # –ù–µ–ø–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ –º–∞—Å—Å–∏–≤–∞
            non_field_mask = array_df['–ü–æ–ª–µ–≤–æ–π'] == 0
            non_field_keys = set(zip(
                array_df.loc[non_field_mask, array_code_col].astype(str).str.strip().fillna(''),
                array_df.loc[non_field_mask, array_project_col].astype(str).str.strip().fillna('')
            ))
            
            # –ö–ª—é—á–∏ –∏–∑ –≥—É–≥–ª —Ç–∞–±–ª–∏—Ü—ã
            google_project_keys = list(zip( 
                result[code_col].astype(str).str.strip().fillna(''),
                result[project_col].astype(str).str.strip().fillna('')
            ))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: –ø—Ä–æ–µ–∫—Ç –µ—Å—Ç—å –≤ –º–∞—Å—Å–∏–≤–µ –ò –æ–Ω –Ω–µ–ø–æ–ª–µ–≤–æ–π
            result['–ü—Ä–æ–µ–∫—Ç –µ—Å—Ç—å –≤ –º–∞—Å—Å–∏–≤–µ, –Ω–æ –Ω–µ –ø–æ–ª–µ–≤–æ–π'] = [
                key in all_array_keys and key in non_field_keys 
                for key in google_project_keys
            ]
        else:
            result['–ü—Ä–æ–µ–∫—Ç –µ—Å—Ç—å –≤ –º–∞—Å—Å–∏–≤–µ, –Ω–æ –Ω–µ –ø–æ–ª–µ–≤–æ–π'] = False
        
        # 4. –ü—Ä–æ–µ–∫—Ç–∞ –Ω–µ—Ç –≤ –º–∞—Å—Å–∏–≤–µ (—Ç–æ–ª—å–∫–æ –ß–µ–∫–∫–µ—Ä)
        if array_df is not None:
            array_code_col = '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã'
            array_project_col = '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞'
            
            # –í—Å–µ –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ –º–∞—Å—Å–∏–≤–∞
            all_array_keys = set(zip(
                array_df[array_code_col].astype(str).str.strip().fillna(''),
                array_df[array_project_col].astype(str).str.strip().fillna('')
            ))
            
            # –¢–æ–ª—å–∫–æ —á–µ–∫–∫–µ—Ä –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ –≥—É–≥–ª
            checker_mask = result[portal_col] == '–ß–µ–∫–∫–µ—Ä'
            google_checker_keys = list(zip(
                result.loc[checker_mask, code_col].astype(str).str.strip().fillna(''),
                result.loc[checker_mask, wave_col].astype(str).str.strip().fillna('')
            ))
            
            # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result['–ü—Ä–æ–µ–∫—Ç–∞ –Ω–µ—Ç –≤ –º–∞—Å—Å–∏–≤–µ'] = False
            result.loc[checker_mask, '–ü—Ä–æ–µ–∫—Ç–∞ –Ω–µ—Ç –≤ –º–∞—Å—Å–∏–≤–µ'] = [
                key not in all_array_keys for key in google_checker_keys
            ]
        else:
            result['–ü—Ä–æ–µ–∫—Ç–∞ –Ω–µ—Ç –≤ –º–∞—Å—Å–∏–≤–µ'] = False
        
        # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        columns = [
            '–§–ò–û –û–ú', project_col, 
            '–°—Ü–µ–Ω–∞—Ä–∏–π, –µ—Å–ª–∏ —Ä–∞–∑–Ω—ã–µ –∫–≤–æ—Ç—ã –∏ —Å—Ä–æ–∫–∏', code_col,
            wave_col,
            '–î–∞—Ç–∞ —Å—Ç–∞—Ä—Ç–∞', '–î–∞—Ç–∞ —Ñ–∏–Ω–∏—à–∞ —Å –ø—Ä–æ–¥–ª–µ–Ω–∏–µ–º',
            '–≤–≤–æ–¥–Ω—ã–µ –∑–∞–ø—Ä–æ—à–µ–Ω—ã / –≤–≤–æ–¥–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã, –≥–æ—Ç–æ–≤–∏—Ç—Å—è —Å—Ç–∞—Ä—Ç / —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª',
            portal_col,
            '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ –ø—É—Å—Ç–æ', '–ü—Ä–æ–µ–∫—Ç–∞ –ù–ï–¢ –≤ –ê–ö', '–ü—Ä–æ–µ–∫—Ç –µ—Å—Ç—å –≤ –º–∞—Å—Å–∏–≤–µ, –Ω–æ –Ω–µ –ø–æ–ª–µ–≤–æ–π', '–ü—Ä–æ–µ–∫—Ç–∞ –Ω–µ—Ç –≤ –º–∞—Å—Å–∏–≤–µ'
        ]

        # –¢–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
        existing_cols = [col for col in columns if col in result.columns]
        result = result[existing_cols]

        # ============================================
        # üÜï –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –û–°–¢–ê–í–õ–Ø–ï–ú –¢–û–õ–¨–ö–û –ü–†–û–ë–õ–ï–ú–ù–´–ï –ü–†–û–ï–ö–¢–´
        # ============================================
        
        # –ö–æ–ª–æ–Ω–∫–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏
        check_columns = ['–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ –ø—É—Å—Ç–æ', '–ü—Ä–æ–µ–∫—Ç–∞ –ù–ï–¢ –≤ –ê–ö', '–ü—Ä–æ–µ–∫—Ç –µ—Å—Ç—å –≤ –º–∞—Å—Å–∏–≤–µ, –Ω–æ –Ω–µ –ø–æ–ª–µ–≤–æ–π', '–ü—Ä–æ–µ–∫—Ç–∞ –Ω–µ—Ç –≤ –º–∞—Å—Å–∏–≤–µ']
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –µ—Å—Ç—å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
        existing_checks = [col for col in check_columns if col in result.columns]
        
        if existing_checks:
            # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫–∏ –≥–¥–µ –•–û–¢–Ø –ë–´ –û–î–ù–ê –ø—Ä–æ–≤–µ—Ä–∫–∞ = True
            problem_mask = result[existing_checks].any(axis=1)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ
            problematic_only = result[problem_mask].copy()
            
            return problematic_only
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame
            return pd.DataFrame()
            


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
data_cleaner = DataCleaner()
















































