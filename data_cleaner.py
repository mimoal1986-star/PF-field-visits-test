# utils/data_cleaner.py
# draft 1.3

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import re
import streamlit as st
import io


class DataCleaner:

    def _find_column(self, df, possible_names):
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–æ–ª–æ–Ω–∫—É –ø–æ –≤–æ–∑–º–æ–∂–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º"""
        for name in possible_names:
            if name in df.columns:
                return name
        return None
    
    def clean_google(self, df):
        """
        –®–∞–≥–∏ 1-7: –û—á–∏—Å—Ç–∫–∞ –ì—É–≥–ª —Ç–∞–±–ª–∏—Ü—ã (–ü—Ä–æ–µ–∫—Ç—ã –°–µ—Ä–≤–∏–∑–æ—Ä–∏—è)
        """
        # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ...
        # (–ø—Ä–æ–ø—É—Å–∫–∞—é –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏, –æ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π)
        
        return df_clean

    def clean_array(self, df):
        """–û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–∞ –ú–∞—Å—Å–∏–≤"""
        if df is None or df.empty:
            st.warning("‚ö†Ô∏è –ú–∞—Å—Å–∏–≤ –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
            return None
        
        df_clean = df.copy()
        original_rows = len(df_clean)
        original_cols = len(df_clean.columns)
        
        st.info(f"üßπ –ù–∞—á–∏–Ω–∞—é –æ—á–∏—Å—Ç–∫—É –ú–∞—Å—Å–∏–≤–∞: {original_rows} —Å—Ç—Ä–æ–∫ √ó {original_cols} –∫–æ–ª–æ–Ω–æ–∫")
        
        # === –£–¥–∞–ª–∏—Ç—å –Ω—É–ª–∏ –≤ –¥–∞—Ç–∞—Ö ===
        st.write("**1Ô∏è‚É£ –ó–∞–º–µ–Ω—è—é –Ω—É–ª–∏ –≤ –¥–∞—Ç–∞—Ö –Ω–∞ —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—É—é –¥–∞—Ç—É (1900-01-01)...**")
        
        DATE_COLUMNS = [
            '–î–∞—Ç–∞ –≤–∏–∑–∏—Ç–∞',
            '–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏', 
            '–î–∞—Ç–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –æ–ø—Ä–æ—Å–∞ –∑–∞ —Ç–∞–π–Ω—ã–º –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–º',
            '–î–∞—Ç–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –æ–ø—Ä–æ—Å–∞ —Ç–∞–π–Ω—ã–º –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–º',
            '–í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è',
            '–í—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–∂–∏–¥–∞–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (–î–∞—Ç–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –æ–ø—Ä–æ—Å–∞?)',
            '–í—Ä–µ–º—è —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è'
        ]
        
        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
        existing_date_cols = [col for col in DATE_COLUMNS if col in df_clean.columns]
        
        if existing_date_cols:
            SURROGATE_DATE = pd.Timestamp('1900-01-01')
            total_replacements = 0
            
            for col in existing_date_cols:
                try:
                    df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce', dayfirst=True)
                    nat_mask = df_clean[col].isna()
                    
                    if nat_mask.any():
                        df_clean.loc[nat_mask, col] = SURROGATE_DATE
                        col_replacements = nat_mask.sum()
                        total_replacements += col_replacements
                        
                        example_indices = nat_mask[nat_mask].index[:3]
                        if len(example_indices) > 0:
                            st.info(f"   '{col}': –∑–∞–º–µ–Ω–µ–Ω–æ {col_replacements} –∑–Ω–∞—á–µ–Ω–∏–π")
                            
                except Exception as e:
                    st.warning(f"   –û—à–∏–±–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ '{col}': {str(e)[:100]}")
            
            if total_replacements > 0:
                st.success(f"   ‚úÖ –ó–∞–º–µ–Ω–µ–Ω–æ {total_replacements} –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç –Ω–∞ {SURROGATE_DATE.date()}")
                st.info("   **–û–±–æ–∑–Ω–∞—á–∞–µ—Ç:** '–°–æ–±—ã—Ç–∏–µ –µ—â–µ –Ω–µ –Ω–∞—Å—Ç—É–ø–∏–ª–æ'")
            else:
                st.info("   ‚ÑπÔ∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        else:
            st.warning(f"   ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏")
        
        # === –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–∞—Å—Å–∏–≤ –Ω–∞ –ù/–î ===
        st.write("**2Ô∏è‚É£ –ó–∞–º–µ–Ω—è—é –ù/–î –Ω–∞ –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è...**")
        
        na_values = ['–ù/–î', '–Ω/–¥', 'N/A', 'n/a', '#–ù/–î', '#–Ω/–¥', 'NA', 'na', '-', '‚Äî', '‚Äì']
        na_replacements = 0
        
        for col in df_clean.columns:
            try:
                for na_val in na_values:
                    mask = df_clean[col].astype(str).str.strip() == na_val
                    if mask.any():
                        df_clean.loc[mask, col] = ''
                        na_replacements += mask.sum()
                
                nan_mask = df_clean[col].astype(str).str.strip().str.lower().isin(['nan', 'none', 'null'])
                if nan_mask.any():
                    df_clean.loc[nan_mask, col] = ''
                    na_replacements += nan_mask.sum()
                    
            except Exception as e:
                st.warning(f"   –û—à–∏–±–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ '{col}': {str(e)[:50]}")
        
        if na_replacements > 0:
            st.success(f"   ‚úÖ –ó–∞–º–µ–Ω–µ–Ω–æ {na_replacements} –∑–Ω–∞—á–µ–Ω–∏–π –ù/–î")
        else:
            st.info("   ‚ÑπÔ∏è –ó–Ω–∞—á–µ–Ω–∏–π –ù/–î –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # === –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–æ–∫–∞—Ö —Å –ù/–î –¥–ª—è –æ—Ç—á–µ—Ç–∞ ===
        st.write("**3Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω—è—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–æ–∫–∞—Ö —Å –ù/–î –¥–ª—è –æ—Ç—á–µ—Ç–∞...**")
        
        # –§–ò–ö–°: –ò—Å–ø–æ–ª—å–∑—É–µ–º df –≤–º–µ—Å—Ç–æ original_df –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ—Ç
        original_df = df.copy()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        
        had_na_mask = pd.Series(False, index=df_clean.index)
        
        for col in df_clean.columns:
            try:
                for na_val in na_values:
                    mask = original_df[col].astype(str).str.strip() == na_val
                    had_na_mask = had_na_mask | mask
            except:
                continue
        
        df_clean.attrs['had_na_rows'] = had_na_mask
        df_clean.attrs['na_rows_count'] = had_na_mask.sum()
        
        st.success(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {had_na_mask.sum()} —Å—Ç—Ä–æ–∫ —Å –ù/–î –¥–ª—è –æ—Ç—á–µ—Ç–∞")
        
        return df_clean

    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ...

    def update_field_projects_flag(self, google_df, autocoding_df):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ–ª–µ '–ü–æ–ª–µ–≤–æ–π' –≤ –≥—É–≥–ª —Ç–∞–±–ª–∏—Ü–µ
        –ü–æ–ª–µ–≤–æ–π = 1 –µ—Å–ª–∏ –∫–æ–¥ –µ—Å—Ç—å –≤ –ê–ö –ò –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ .01/.02
        """
        try:
            if google_df is None or google_df.empty:
                st.warning("‚ö†Ô∏è –ì—É–≥–ª —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞—è")
                return google_df
                
            if autocoding_df is None or autocoding_df.empty:
                st.warning("‚ö†Ô∏è –ê–≤—Ç–æ–∫–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—É—Å—Ç–∞—è")
                return google_df
            
            google_df_clean = google_df.copy()
            autocoding_df_clean = autocoding_df.copy()
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–ª—é—á–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            google_code_col = self._find_column(google_df_clean, [
                '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ RU00.000.00.01SVZ24',
                '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞',
                'Project Code',
                '–ö–æ–¥'
            ])
            
            if not google_code_col:
                st.error("‚ùå –í –≥—É–≥–ª —Ç–∞–±–ª–∏—Ü–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –∫–æ–¥–æ–º –ø—Ä–æ–µ–∫—Ç–∞")
                return google_df
            
            ak_code_col = self._find_column(autocoding_df_clean, [
                '–ò–¢–û–ì–û –ö–û–î',
                '–ò—Ç–æ–≥–æ–ö–æ–¥',
                '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞',
                '–ö–æ–¥'
            ])
            
            ak_direction_col = self._find_column(autocoding_df_clean, [
                '–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ',
                'Direction',
                '–ù–∞–ø—Ä'
            ])
            
            if not ak_code_col:
                st.error("‚ùå –í –∞–≤—Ç–æ–∫–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '–ò–¢–û–ì–û –ö–û–î'")
                return google_df
                
            if not ak_direction_col:
                st.warning("‚ö†Ô∏è –í –∞–≤—Ç–æ–∫–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ'")
                autocoding_df_clean[ak_direction_col] = ''
            
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            autocoding_df_clean[ak_code_col] = autocoding_df_clean[ak_code_col].astype(str).str.strip()
            autocoding_df_clean[ak_direction_col] = autocoding_df_clean[ak_direction_col].astype(str).str.strip()
            google_df_clean[google_code_col] = google_df_clean[google_code_col].astype(str).str.strip()
            
            # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π
            allowed_directions = {'.01', '.02', '01', '02', '0.01', '0.02', '1', '2'}
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ {–∫–æ–¥: —è–≤–ª—è–µ—Ç—Å—è_–ø–æ–ª–µ–≤—ã–º}
            field_codes = set()
            
            for _, row in autocoding_df_clean.iterrows():
                try:
                    code = str(row[ak_code_col])
                    direction = str(row[ak_direction_col])
                    
                    if code and code.lower() not in ['nan', 'none', 'null', '']:
                        if direction in allowed_directions:
                            field_codes.add(code)
                except Exception:
                    continue
            
            st.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(field_codes)} –ø–æ–ª–µ–≤—ã—Ö –∫–æ–¥–æ–≤ –≤ –∞–≤—Ç–æ–∫–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É '–ü–æ–ª–µ–≤–æ–π'
            if '–ü–æ–ª–µ–≤–æ–π' not in google_df_clean.columns:
                google_df_clean['–ü–æ–ª–µ–≤–æ–π'] = 0
            
            # –í–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            google_codes = google_df_clean[google_code_col].astype(str)
            
            def check_field(code):
                if pd.isna(code) or str(code).lower() in ['nan', 'none', 'null', '']:
                    return 0
                return 1 if str(code) in field_codes else 0
            
            google_df_clean['–ü–æ–ª–µ–≤–æ–π'] = google_codes.apply(check_field).astype(int)
            
            updated_count = (google_df_clean['–ü–æ–ª–µ–≤–æ–π'] == 1).sum()
            st.success(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª–µ '–ü–æ–ª–µ–≤–æ–π': {updated_count} –ø–æ–ª–µ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤")
            
            return google_df_clean
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ update_field_projects_flag: {str(e)[:100]}")
            return google_df

    def add_field_flag_to_array(self, array_df, google_df):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç '–ü–æ–ª–µ–≤–æ–π' –≤ –º–∞—Å—Å–∏–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥—É–≥–ª —Ç–∞–±–ª–∏—Ü—ã
        """
        try:
            if array_df is None or array_df.empty:
                st.warning("‚ö†Ô∏è –ú–∞—Å—Å–∏–≤ –ø—É—Å—Ç–æ–π")
                return array_df
                
            if google_df is None or google_df.empty:
                st.warning("‚ö†Ô∏è –ì—É–≥–ª —Ç–∞–±–ª–∏—Ü–∏—è –ø—É—Å—Ç–∞—è")
                return array_df
            
            array_df_clean = array_df.copy()
            google_df_clean = google_df.copy()
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫–∏ —Å –∫–æ–¥–∞–º–∏
            array_code_col = self._find_column(array_df_clean, [
                '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã',
                '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞',
                'Project Code',
                '–ö–æ–¥'
            ])
            
            google_code_col = self._find_column(google_df_clean, [
                '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ RU00.000.00.01SVZ24',
                '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞',
                'Project Code',
                '–ö–æ–¥'
            ])
            
            if not array_code_col:
                st.error("‚ùå –í –º–∞—Å—Å–∏–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã'")
                return array_df
                
            if not google_code_col:
                st.error("‚ùå –í –≥—É–≥–ª —Ç–∞–±–ª–∏—Ü–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –∫–æ–¥–æ–º –ø—Ä–æ–µ–∫—Ç–∞")
                return array_df
            
            if '–ü–æ–ª–µ–≤–æ–π' not in google_df_clean.columns:
                st.warning("‚ö†Ô∏è –í –≥—É–≥–ª —Ç–∞–±–ª–∏—Ü–µ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ü–æ–ª–µ–≤–æ–π', —Å–æ–∑–¥–∞—é –Ω—É–ª–µ–≤—É—é")
                google_df_clean['–ü–æ–ª–µ–≤–æ–π'] = 0
            
            # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            array_df_clean[array_code_col] = array_df_clean[array_code_col].astype(str).str.strip()
            google_df_clean[google_code_col] = google_df_clean[google_code_col].astype(str).str.strip()
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è {–∫–æ–¥: –ø–æ–ª–µ–≤–æ–µ_–∑–Ω–∞—á–µ–Ω–∏–µ}
            code_to_field = {}
            
            for idx, row in google_df_clean.iterrows():
                try:
                    code = str(row[google_code_col])
                    if code and code.lower() not in ['nan', 'none', 'null', '']:
                        field_val = row.get('–ü–æ–ª–µ–≤–æ–π', 0)
                        try:
                            code_to_field[code] = int(field_val) if not pd.isna(field_val) else 0
                        except (ValueError, TypeError):
                            code_to_field[code] = 0
                except Exception:
                    continue
            
            st.info(f"üîç –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(code_to_field)} —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π –∫–æ–¥–æ–≤")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É –≤ –º–∞—Å—Å–∏–≤
            array_df_clean['–ü–æ–ª–µ–≤–æ–π'] = 0
            
            def get_field_value(code):
                if pd.isna(code) or str(code).lower() in ['nan', 'none', 'null', '']:
                    return 0
                return code_to_field.get(str(code), 0)
            
            array_codes = array_df_clean[array_code_col].astype(str)
            array_df_clean['–ü–æ–ª–µ–≤–æ–π'] = array_codes.apply(get_field_value).astype(int)
            
            filled_count = (array_df_clean['–ü–æ–ª–µ–≤–æ–π'] == 1).sum()
            st.success(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω '–ü–æ–ª–µ–≤–æ–π' –≤ –º–∞—Å—Å–∏–≤: {filled_count} –ø–æ–ª–µ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")
            
            return array_df_clean
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ add_field_flag_to_array: {str(e)[:100]}")
            return array_df

    def split_array_by_field_flag(self, array_df):
        """
        –†–∞–∑–¥–µ–ª—è–µ—Ç –º–∞—Å—Å–∏–≤ –Ω–∞ –ü–æ–ª–µ–≤—ã–µ –∏ –ù–µ–ø–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ 8 —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        """
        try:
            if array_df is None or array_df.empty:
                st.warning("‚ö†Ô∏è –ú–∞—Å—Å–∏–≤ –ø—É—Å—Ç–æ–π")
                return None, None
            
            array_df_clean = array_df.copy()
            
            if '–ü–æ–ª–µ–≤–æ–π' not in array_df_clean.columns:
                st.error("‚ùå –í –º–∞—Å—Å–∏–≤–µ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ü–æ–ª–µ–≤–æ–π'")
                return None, None
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–ø–ø–∏–Ω–≥ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            column_mapping = {
                '–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞': ['–ö–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞', '–ö–æ–¥ –∞–Ω–∫–µ—Ç—ã', 'Project Code', '–ö–æ–¥'],
                '–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞': ['–ò–º—è –∫–ª–∏–µ–Ω—Ç–∞', '–ö–ª–∏–µ–Ω—Ç', 'Client', 'Client Name'],
                '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞': ['–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', '–ü—Ä–æ–µ–∫—Ç', 'Project', 'Project Name'],
                '–ó–û–î': ['–ó–û–î', 'ZOD', '–ó–æ–¥', 'zod'],
                '–ê–°–°': ['–ê–°–°', 'ASS', '–ê—Å—Å', 'ass'],
                '–≠–ú': ['–≠–ú', 'EM', '–ï–º', 'em'],
                '–†–µ–≥–∏–æ–Ω short': ['–†–µ–≥–∏–æ–Ω short', '–†–µ–≥–∏–æ–Ω_short', 'Region_short', 'Short Region'],
                '–†–µ–≥–∏–æ–Ω': ['–†–µ–≥–∏–æ–Ω', 'Region', '—Ä–µ–≥']
            }
            
            # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
            actual_columns = {}
            missing_columns = []
            
            for std_col, possible_names in column_mapping.items():
                found_col = self._find_column(array_df_clean, possible_names)
                if found_col:
                    actual_columns[std_col] = found_col
                else:
                    missing_columns.append(std_col)
            
            if missing_columns:
                st.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_columns)}")
                for col in missing_columns:
                    array_df_clean[col] = ''
                    actual_columns[col] = col
            
            # –û—Ç–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ + –ü–æ–ª–µ–≤–æ–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            selected_cols = list(actual_columns.values()) + ['–ü–æ–ª–µ–≤–æ–π']
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            field_mask = array_df_clean['–ü–æ–ª–µ–≤–æ–π'] == 1
            field_projects = array_df_clean.loc[field_mask, selected_cols].copy()
            non_field_projects = array_df_clean.loc[~field_mask, selected_cols].copy()
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏
            reverse_mapping = {v: k for k, v in actual_columns.items()}
            
            if not field_projects.empty:
                field_projects = field_projects.rename(columns=reverse_mapping)
                field_projects = field_projects.drop(columns=['–ü–æ–ª–µ–≤–æ–π'], errors='ignore')
            
            if not non_field_projects.empty:
                non_field_projects = non_field_projects.rename(columns=reverse_mapping)
                non_field_projects = non_field_projects.drop(columns=['–ü–æ–ª–µ–≤–æ–π'], errors='ignore')
            
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 8 –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            final_columns = list(column_mapping.keys())
            
            if not field_projects.empty:
                field_projects = field_projects.reindex(columns=final_columns)
            
            if not non_field_projects.empty:
                non_field_projects = non_field_projects.reindex(columns=final_columns)
            
            st.success(f"‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:")
            st.info(f"   üìä –ü–æ–ª–µ–≤—ã–µ: {len(field_projects)} –∑–∞–ø–∏—Å–µ–π")
            st.info(f"   üìä –ù–µ–ø–æ–ª–µ–≤—ã–µ: {len(non_field_projects)} –∑–∞–ø–∏—Å–µ–π")
            
            return field_projects, non_field_projects
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ split_array_by_field_flag: {str(e)[:100]}")
            return None, None

    def export_split_array_to_excel(self, field_df, non_field_df, filename="—Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–π_–º–∞—Å—Å–∏–≤"):
        """
        –°–æ–∑–¥–∞–µ—Ç Excel —Å –≤–∫–ª–∞–¥–∫–∞–º–∏ –ü–æ–ª–µ–≤—ã–µ/–ù–µ–ø–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
        """
        try:
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # –ü–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
                if field_df is not None and not field_df.empty:
                    field_df.to_excel(writer, sheet_name='–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False)
                else:
                    pd.DataFrame({'–°–æ–æ–±—â–µ–Ω–∏–µ': ['–ù–µ—Ç –ø–æ–ª–µ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤']}).to_excel(
                        writer, sheet_name='–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False
                    )
                
                # –ù–µ–ø–æ–ª–µ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
                if non_field_df is not None and not non_field_df.empty:
                    non_field_df.to_excel(writer, sheet_name='–ù–ï–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False)
                else:
                    pd.DataFrame({'–°–æ–æ–±—â–µ–Ω–∏–µ': ['–ù–µ—Ç –Ω–µ–ø–æ–ª–µ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤']}).to_excel(
                        writer, sheet_name='–ù–ï–ü–û–õ–ï–í–´–ï_–ü–†–û–ï–ö–¢–´', index=False
                    )
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                stats_data = {
                    '–ú–µ—Ç—Ä–∏–∫–∞': ['–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π', '–ü–æ–ª–µ–≤—ã–µ', '–ù–µ–ø–æ–ª–µ–≤—ã–µ', '–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏'],
                    '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                        (len(field_df) if field_df is not None else 0) + 
                        (len(non_field_df) if non_field_df is not None else 0),
                        len(field_df) if field_df is not None else 0,
                        len(non_field_df) if non_field_df is not None else 0,
                        pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
                    ]
                }
                pd.DataFrame(stats_data).to_excel(writer, sheet_name='–°–¢–ê–¢–ò–°–¢–ò–ö–ê', index=False)
            
            output.seek(0)
            return output
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel: {str(e)[:100]}")
            return None


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä (–¢–û–õ–¨–ö–û –û–î–ò–ù –†–ê–ó –í –ö–û–ù–¶–ï)
data_cleaner = DataCleaner()
